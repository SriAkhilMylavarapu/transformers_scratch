{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ce921-ed56-466c-a173-081c6fb26cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e734bac-4f75-4877-8ae8-e7f73338efdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math,copy,re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.simplefilter(\"ignore\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4ba11-ea1b-42f2-85b7-ce93edd1d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, self.d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0,self.d_model,2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** (i/self.d_model)))\n",
    "                if i+1 < self.d_model:\n",
    "                    pe[pos, i + 1] = math.cos(pos / (10000 ** (i/self.d_model)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe) #dont use for training\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        x = x + torch.Tensor(self.pe[:,:seq_len])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd99be-9e97-4527-be18-a4ae70a35bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_model = 512, num_heads = 8\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        #We use weights of size (d_model, d_model) to represent the weights of all heads, the first (d_model, d_k) would be the weights of 1st head and so on.\n",
    "        self.W_q = nn.Linear(d_model, d_model) #weights for Queries\n",
    "        self.W_k = nn.Linear(d_model, d_model) #weights for Keys\n",
    "        self.W_v = nn.Linear(d_model, d_model) #weights for Values\n",
    "        self.W_o = nn.Linear(d_model, d_model) #weights for Outputs\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None): #Q,K,V are in the shape [batch_size, num_heads, seq_length, d_k]\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)  #dot product\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)  #masking so softmax assigns them 0 probability\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)  #softmax\n",
    "        output = torch.matmul(attn_probs, V) #weighted distribution of Values using softmax\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)  #splits into d_k length vectors for multihead\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model) #reverses what split_heads does to return a d_model vector output\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q)) #split_heads is used here to represent the multiple heads \n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask) #Gets attention\n",
    "        output = self.W_o(self.combine_heads(attn_output)) #Linear output layer\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4aa029-198f-4491-87d4-3875f98e4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two linear transformations and a ReLU activation\n",
    "#d_ff = 2048\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d09679-7361-454c-83e7-88313a6922d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask) #get self attention\n",
    "        x = self.norm1(x + self.dropout(attn_output)) #residual add and norm\n",
    "        ff_output = self.feed_forward(x) #feed forward\n",
    "        x = self.norm2(x + self.dropout(ff_output)) #residual add and norm\n",
    "        return x #encoder output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb28d1-3a2d-4a1f-b659-e1226a89a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask): #masks are used so the decoder layer can't look further than the words it has predicted\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask) #masked self attention\n",
    "        x = self.norm1(x + self.dropout(attn_output)) #residual add and norm\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask) #masked cross attention\n",
    "        x = self.norm2(x + self.dropout(attn_output)) #residual add and norm\n",
    "        ff_output = self.feed_forward(x) #feed forward\n",
    "        x = self.norm3(x + self.dropout(ff_output)) #residual add and norm\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd6a8c-93ea-4f82-9058-ed2bcca0aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model) #word embedding for source language\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model) #word embedding for target language\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length) #positional encoding\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)]) #encoder layers (6)\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)]) #decoder layers (6)\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size) #linear layer for decoding output\n",
    "        self.dropout = nn.Dropout(dropout) #dropout after positional encoding\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2) #creates a boolean mask of shape (batch_size, 1, 1, seq_length)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3) #makes it ignore padding tokens\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device) #makes it not look ahead\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src))) #word and positional embedding\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded  #run through num_layers of encoders\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded  #run through num_layers of decoders\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output) #final linear layer\n",
    "        tgt_word_probs = torch.softmax(output, dim=-1)  #softmax\n",
    "        return tgt_word_probs #final decoded output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02f898e-af89-410d-8a19-dd38ac0f0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(file_path, lang, vocab_size=20000):\n",
    "    tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    \n",
    "    trainer = WordPieceTrainer(\n",
    "        vocab_size=vocab_size,\n",
    "        special_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\", \"[EOS]\"]\n",
    "    )\n",
    "    def batch_iterator():\n",
    "        batch_size = 1000\n",
    "        for chunk in pd.read_csv(file_path, chunksize=batch_size, on_bad_lines=\"skip\", encoding=\"utf-8\", lineterminator='\\n'):  # Read in chunks\n",
    "            chunk = chunk.dropna()\n",
    "            yield chunk[lang].tolist()\n",
    "    \n",
    "    tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "794c49a9-3b9d-42df-8b76-894ec4113986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_tokenizers(filepath, base_path=\"tokenizers\"):\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "    src_path = os.path.join(base_path, \"src_tokenizer.json\")\n",
    "    tgt_path = os.path.join(base_path, \"tgt_tokenizer.json\")\n",
    "    \n",
    "    if os.path.exists(src_path):\n",
    "        print(f\"Loading existing source tokenizer from {src_path}\")\n",
    "        src_tokenizer = Tokenizer.from_file(src_path)\n",
    "    else:\n",
    "        print(f\"Creating new source tokenizer and saving to {src_path}\")\n",
    "        src_tokenizer = create_tokenizer(filepath, \"de\")\n",
    "        src_tokenizer.save(src_path)\n",
    "    \n",
    "    if os.path.exists(tgt_path):\n",
    "        print(f\"Loading existing target tokenizer from {tgt_path}\")\n",
    "        tgt_tokenizer = Tokenizer.from_file(tgt_path)\n",
    "    else:\n",
    "        print(f\"Creating new target tokenizer and saving to {tgt_path}\")\n",
    "        tgt_tokenizer = create_tokenizer(filepath, \"en\")\n",
    "        tgt_tokenizer.save(tgt_path)\n",
    "    \n",
    "    return src_tokenizer, tgt_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e59a0d24-e68d-47be-86de-2c62b65d04bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new source tokenizer and saving to tokenizers\\src_tokenizer.json\n",
      "Creating new target tokenizer and saving to tokenizers\\tgt_tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer, tgt_tokenizer = get_or_create_tokenizers(\"wmt14_translate_de-en_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186839cb-021c-4848-a0b7-56398b47011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wmt14_translate_de-en_train.csv\", nrows=10, encoding=\"utf-8\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def9ee1-1305-49cb-9055-0c12ef161cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data, src_tokenizer, tgt_tokenizer, max_length=64):\n",
    "        self.data = data\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Tokenize source and target texts\n",
    "        src_tokens = self.src_tokenizer.encode(item['en'])\n",
    "        tgt_tokens = self.tgt_tokenizer.encode(item['de'])\n",
    "        \n",
    "        # Add BOS and EOS tokens\n",
    "        src_tokens = [self.src_tokenizer.token_to_id(\"[BOS]\")] + src_tokens.ids + [self.src_tokenizer.token_to_id(\"[EOS]\")]\n",
    "        tgt_tokens = [self.tgt_tokenizer.token_to_id(\"[BOS]\")] + tgt_tokens.ids + [self.tgt_tokenizer.token_to_id(\"[EOS]\")]\n",
    "        \n",
    "        # Pad sequences\n",
    "        src_tokens = self._pad_sequence(src_tokens)\n",
    "        tgt_tokens = self._pad_sequence(tgt_tokens)\n",
    "        \n",
    "        return torch.tensor(src_tokens), torch.tensor(tgt_tokens)\n",
    "\n",
    "    def _pad_sequence(self, tokens):\n",
    "        pad_id = self.src_tokenizer.token_to_id(\"[PAD]\")\n",
    "        if len(tokens) < self.max_length:\n",
    "            tokens = tokens + [pad_id] * (self.max_length - len(tokens))\n",
    "        else:\n",
    "            tokens = tokens[:self.max_length-1] + [self.src_tokenizer.token_to_id(\"[EOS]\")]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259c76f-bf56-47d2-8bbd-5307b911bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        self.file_path = file_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = pd.read_csv(self.file_path, skiprows=idx, nrows=1)  # Load only 1 row\n",
    "        data = chunk.values[0]  # Convert row to NumPy\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(1 for _ in open(self.file_path)) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6339507d-72b1-4bab-b4b0-771e2be3121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data, src_tokenizer, tgt_tokenizer, max_length=64):\n",
    "        self.data = data\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Tokenize source and target texts\n",
    "        src_tokens = self.src_tokenizer.encode(item['translation']['en'])\n",
    "        tgt_tokens = self.tgt_tokenizer.encode(item['translation']['de'])\n",
    "        \n",
    "        # Add BOS and EOS tokens\n",
    "        src_tokens = [self.src_tokenizer.token_to_id(\"[BOS]\")] + src_tokens.ids + [self.src_tokenizer.token_to_id(\"[EOS]\")]\n",
    "        tgt_tokens = [self.tgt_tokenizer.token_to_id(\"[BOS]\")] + tgt_tokens.ids + [self.tgt_tokenizer.token_to_id(\"[EOS]\")]\n",
    "        \n",
    "        # Pad sequences\n",
    "        src_tokens = self._pad_sequence(src_tokens)\n",
    "        tgt_tokens = self._pad_sequence(tgt_tokens)\n",
    "        \n",
    "        return torch.tensor(src_tokens), torch.tensor(tgt_tokens)\n",
    "\n",
    "    def _pad_sequence(self, tokens):\n",
    "        pad_id = self.src_tokenizer.token_to_id(\"[PAD]\")\n",
    "        if len(tokens) < self.max_length:\n",
    "            tokens = tokens + [pad_id] * (self.max_length - len(tokens))\n",
    "        else:\n",
    "            tokens = tokens[:self.max_length-1] + [self.src_tokenizer.token_to_id(\"[EOS]\")]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6e4c9-788f-45ed-a3e8-caba2b497d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = 5000\n",
    "tgt_vocab_size = 5000\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout).to(device)\n",
    "\n",
    "# Generate random sample data\n",
    "src_data = torch.randint(1, src_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)\n",
    "tgt_data = torch.randint(1, tgt_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)\n",
    "src_data = src_data.to(device)\n",
    "tgt_data = tgt_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea9b58c-32a1-4c86-b440-9ab39728448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(transformer.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28fda3-9f92-4b1d-8f71-ea0ff061d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = transformer(src_data, tgt_data[:, :-1])\n",
    "    loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cddfd-4858-4c21-bf51-fddb1ed26132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb20b469-e9cb-4b0b-808c-7c81ea15c4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46475567-0848-4385-970a-de04806d4d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305c422-94c5-4b38-8b4e-76108f7c1115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8488fd-8c82-4d1a-9458-0600fa2f3594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
